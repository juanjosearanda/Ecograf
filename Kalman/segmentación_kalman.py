# -*- coding: utf-8 -*-
"""Segmentación Kalman

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18xjgrlomWqyfCMqxLLOnKwSaezPf8n4Q

Gemini 3.0 Pro https://gemini.google.com/app/4f5a83942bf3de38

Basándome en el documento técnico "Segmentación de Secuencias de imágenes ecocardiográficas bidimensionales"

Muestra la ecuación de diferencia:$$D_{k+1}(p) = |I_{k+1}(p) - B_{k+1}est(p)|$$Muestra la condición de la máscara:$$N(p) = 255 \text{ si } D > \text{Umbral}, 0 \text{ en otro caso}$$

Conceptos a enfatizar:Adaptabilidad: Explicar que el corazón se mueve rápido, por eso los parámetros del filtro ($\alpha=0.01$ y $\beta=0.1$) están ajustados para alta movilidad, a diferencia de sistemas de vigilancia de tráfico, por ejemplo.

Aquí tienes el script de Python completo. He utilizado la biblioteca **OpenCV** y **NumPy** para implementar las ecuaciones matriciales descritas en el paper.

He incluido un generador de **"Datos Sintéticos"** (un círculo moviéndose y pulsando) dentro del mismo script. Esto significa que puedes ejecutar el código inmediatamente para ver cómo funciona el algoritmo sin necesidad de tener un vídeo de ecocardiografía real a mano.

### Cómo funciona el script:

1.  **Clase `KalmanSegmenter`**: Encapsula toda la lógica matemática del paper (Predicción, Actualización, Detección).
2.  **Simulación**: Crea una animación de un "ventrículo" simulado con ruido para probar el filtro.
3.  **Visualización**: Muestra 3 ventanas:
      * *Original*: La imagen de entrada (ruidosa).
      * *Fondo Estimado*: Lo que el algoritmo cree que es fondo estático.
      * *Máscara (Segmentación)*: El resultado final (el tejido detectado).

http://googleusercontent.com/immersive_entry_chip/0

### Instrucciones de uso:

1.  Asegúrate de tener instaladas las librerías necesarias:
    ````bash
    pip install opencv-python numpy
    2.  Ejecuta el archivo:
    ```bash
    python segmentacion_kalman.py

    ````

### Lo que verás en las ventanas:

  * **Ventana 1 (Entrada):** Verás un anillo ruidoso que se contrae y expande, simulando un ventrículo izquierdo en un ecocardiograma. El ruido de fondo ("speckle") está diseñado para dificultar la detección simple.
  * **Ventana 2 (Fondo Estimado):** Verás una imagen algo "fantasmal". Esto es lo que el filtro de Kalman *predice* que es el fondo estático. Notarás que el filtro intenta "borrar" el anillo en movimiento, dejándolo borroso.
  * **Ventana 3 (Segmentación Detectada):** Verás el anillo resaltado en verde. Esto demuestra que el algoritmo está separando exitosamente el objeto en movimiento (el anillo) del ruido estático, tal como describe el paper.

Si deseas probarlo con un **vídeo real**, solo tienes que descomentar la línea `cap = cv2.VideoCapture('tu_video.mp4')` y reemplazar la llamada a `generate_synthetic_heart_frame` por `ret, frame = cap.read()`.
"""

import cv2
import numpy as np

class KalmanSegmenter:
    """
    Implementación del algoritmo de segmentación basado en el paper:
    'Segmentación de secuencias de imágenes ecocardiográficas bidimensionales'
    (J. J. Aranda, ICID, 1996-97)
    """
    def __init__(self, height, width):
        # Parámetros del paper
        self.alpha = 0.01  # Ganancia baja para zonas de movimiento (Foreground)
        self.beta = 0.1    # Ganancia alta para zonas de fondo (Background)
        self.a12 = 0.25    # Dinámica de variación del fondo
        self.a22 = 0.25
        self.maxdif = 16   # Umbral de detección (Threshold)

        # Estado inicial (Paso 0 del paper)
        # B_est: Fondo estimado
        # B_med: Componente auxiliar de medición/velocidad de cambio
        # Se usan floats para precisión en los cálculos matriciales
        self.B_est = np.full((height, width), 127.5, dtype=np.float32)
        self.B_med = np.zeros((height, width), dtype=np.float32)

        # Máscara inicial (M_1(p) = 255 según el paper)
        self.mask = np.ones((height, width), dtype=np.float32)

        # Matriz de transición A
        # [ 1   a12 ]
        # [ 0   a22 ]
        self.A = np.array([[1, self.a12],
                           [0, self.a22]], dtype=np.float32)

    def process_frame(self, frame_gray):
        """
        Procesa un solo cuadro y retorna la máscara binaria.
        """
        # Convertir entrada a float para cálculos
        I_k = frame_gray.astype(np.float32)

        # --- Paso 1: Actualización de la medición ---

        # Calcular matriz de ganancia G adaptativa pixel a pixel
        # Si Mask=1 (Objeto), usa alpha. Si Mask=0 (Fondo), usa beta.
        # Nota: self.mask está normalizada (0.0 o 1.0) para esta operación matemática
        G = self.alpha * self.mask + self.beta * (1.0 - self.mask)

        # Innovación: Diferencia entre imagen actual y fondo estimado
        innovation = I_k - self.B_est

        # Corrección del estado (Ecuación matricial simplificada)
        # B_correc = B_est + G * (I - B_est)
        B_est_corr = self.B_est + G * innovation
        B_med_corr = self.B_med + G * innovation # El paper implica G idéntico para ambos componentes

        # --- Paso 2: Predicción del fondo (para el siguiente k+1) ---

        # Aplicación de la matriz A:
        # B_{k+1}_est = B_k_corr_est + a12 * B_k_corr_med
        # B_{k+1}_med = 0            + a22 * B_k_corr_med

        self.B_est = B_est_corr + self.a12 * B_med_corr
        self.B_med = self.a22 * B_med_corr

        # Asegurar rangos válidos de imagen (0-255) para la estimación
        self.B_est = np.clip(self.B_est, 0, 255)

        # --- Paso 3: Detección (Generación de la nueva máscara) ---

        # Diferencia absoluta
        D_k = np.abs(I_k - self.B_est)

        # Umbralización (Thresholding)
        # Genera nueva máscara: 1.0 si diferencia > maxdif, 0.0 si no
        new_mask = np.where(D_k >= self.maxdif, 1.0, 0.0)

        # Actualizamos la máscara para la siguiente iteración
        self.mask = new_mask

        # Retornar máscara formateada como imagen uint8 (0-255) para visualización
        return (self.mask * 255).astype(np.uint8), self.B_est.astype(np.uint8)

def generate_synthetic_heart_frame(t, width=320, height=240):
    """
    Genera un cuadro sintético que simula un ventrículo latiendo con ruido.
    """
    img = np.zeros((height, width), dtype=np.uint8)

    # Simular ruido de fondo (speckle noise típico de ultrasonido)
    noise = np.random.normal(50, 15, (height, width)).astype(np.uint8)
    img = cv2.add(img, noise)

    # Simular corazón (círculo que se contrae y expande)
    center = (width // 2, height // 2)
    # Radio oscila con el tiempo t
    radius = int(60 + 20 * np.sin(t * 0.2))
    thickness = 15

    # Dibujar "miocardio" (tejido brillante)
    cv2.circle(img, center, radius, (200), thickness)

    # Añadir ruido extra al tejido para hacerlo difícil
    tissue_noise = np.random.normal(0, 20, (height, width)).astype(np.uint8)
    mask_circle = np.zeros_like(img)
    cv2.circle(mask_circle, center, radius, (1), thickness)
    img = np.where(mask_circle == 1, cv2.add(img, tissue_noise), img)

    return img

def main():
    print("Iniciando Simulación de Segmentación Cardíaca...")
    print("Pulsa 'q' para salir.")

    # Video real:
    cap = cv2.VideoCapture('/home/test/Vídeos/practica250408_vlc_sd_low.mp4')

    # width, height = 320, 240 # Video simulado
    # Source - https://stackoverflow.com/a
    # Posted by GGEv
    # Retrieved 2025-11-27, License - CC BY-SA 4.0

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    segmenter = KalmanSegmenter(height, width)

    t = 0
    while True:
        # 1. Obtener cuadro (Sintético o de Video Real)
        # Para usar video real:
        ret, frame = cap.read();
        if not ret:
            print("Fallo al leer video")
            break

        # Si las imágenes del vídeo están en color (BGR):
        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Video simulado:
        # frame_gray = generate_synthetic_heart_frame(t, width, height)
        t += 1

        # 2. Procesar con el algoritmo del paper
        mask, background_est = segmenter.process_frame(frame_gray)

        # 3. Visualización
        # Colorear la máscara para verla mejor sobre la original (verde)
        mask_color = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
        mask_color[:, :, 0] = 0 # B
        mask_color[:, :, 2] = 0 # R
        # (Solo canal G activo)

        frame_color = cv2.cvtColor(frame_gray, cv2.COLOR_GRAY2BGR)

        # Superponer: Imagen Original + Máscara Verde semitransparente
        overlay = cv2.addWeighted(frame_color, 0.7, mask_color, 0.3, 0)

        # Mostrar resultados
        cv2.imshow('1. Entrada (Simulacion ECO)', frame_gray)
        cv2.imshow('2. Fondo Estimado (Kalman)', background_est)
        cv2.imshow('3. Segmentacion Detectada', overlay)

        # Control de velocidad (30ms) y salida
        if cv2.waitKey(30) & 0xFF == ord('q'):
            break

    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()